{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2022 Dev-Matching.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jK4hycJAYEc_x0dUEVqq0iqYTHOMZZLt",
      "authorship_tag": "ABX9TyNv3Zl8erQNf4/DE+ClttIV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thogood212/dev_matching2022/blob/main/2022_Dev_Matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#시계열 데이터를 사용한 행동 분류\n",
        "\n",
        "##[목표] 주어진 데이터를 활용하여 F1 score(macro)를 최대로 높이세요.\n",
        "\n"
      ],
      "metadata": {
        "id": "70Pe11RZFfhV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t27RFf3jFdTs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "lr = 0.0001\n",
        "\n",
        "epochs = 500\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxdWeFLtFrGt",
        "outputId": "0bc954aa-cdd0-4a69-9afb-be232df036cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset0_classes = os.listdir('/content/drive/MyDrive/dev_ML/dataset0/train/')\n",
        "dataset0_label_encoder = LabelEncoder()\n",
        "\n",
        "dataset0_label_encoder.fit(dataset0_classes)\n",
        "print(dataset0_label_encoder.classes_)\n",
        "print(len(dataset0_label_encoder.classes_))\n",
        "\n",
        "dataset1_classes = os.listdir('/content/drive/MyDrive/dev_ML/dataset1/train/')\n",
        "dataset1_label_encoder = LabelEncoder()\n",
        "\n",
        "dataset1_label_encoder.fit(dataset1_classes)\n",
        "print(dataset1_label_encoder.classes_)\n",
        "print(len(dataset1_label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GaAo77IF03O",
        "outputId": "5c559f11-9b2e-4a0c-bd83-cefbd706b591"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['class0' 'class1' 'class11' 'class12' 'class13' 'class14' 'class15'\n",
            " 'class2' 'class3' 'class4' 'class5' 'class6' 'class7' 'class8' 'class9']\n",
            "15\n",
            "['class0' 'class1' 'class10' 'class2' 'class3' 'class4' 'class5' 'class6'\n",
            " 'class7' 'class8' 'class9']\n",
            "11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##데이터셋/데이터로더"
      ],
      "metadata": {
        "id": "EJKkzec4YbfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(dataset_dir):\n",
        "  X, y = [], []\n",
        "  labels = os.listdir(dataset_dir)\n",
        "  for label in labels:\n",
        "    file_list = os.listdir(dataset_dir + label + '/')\n",
        "    for f in file_list:\n",
        "      temp = pd.read_csv(dataset_dir + label + '/' + f)\n",
        "      X.append(torch.from_numpy(temp.values))\n",
        "      y.append(label)\n",
        "  X = pad_sequence(X, batch_first=True)\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "Xr6IZMOPF0yg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋 주소\n",
        "dataset0_train_dir = '/content/drive/MyDrive/dev_ML/dataset0/train/'\n",
        "dataset0_test_dir = '/content/drive/MyDrive/dev_ML/dataset0/test/'\n",
        "dataset1_train_dir = '/content/drive/MyDrive/dev_ML/dataset1/train/'\n",
        "dataset1_test_dir = '/content/drive/MyDrive/dev_ML/dataset1/test/'"
      ],
      "metadata": {
        "id": "fy49PmUUIAF8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset0's training/test datasets & dataloader\n",
        "dataset0_X_train, dataset0_y_train = create_dataset(dataset0_train_dir)\n",
        "dataset0_y_train = dataset0_label_encoder.transform(dataset0_y_train)\n",
        "\n",
        "dataset0_X_test, dataset0_y_test = create_dataset(dataset0_test_dir)\n",
        "dataset0_y_test = dataset0_label_encoder.transform(dataset0_y_test)\n",
        "\n",
        "dataset0_train_dataset = TensorDataset(torch.tensor(dataset0_X_train).float(), torch.from_numpy(dataset0_y_train))\n",
        "dataset0_test_dataset = TensorDataset(torch.tensor(dataset0_X_test).float(), torch.from_numpy(dataset0_y_test))\n",
        "\n",
        "dataset0_train_dataloader = DataLoader(dataset0_train_dataset,\n",
        "                                       batch_size=batch_size)\n",
        "dataset0_test_dataloader= DataLoader(dataset0_test_dataset,\n",
        "                                     batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9YZe0arF8lW",
        "outputId": "5b525b82-7e23-4557-ff71-c392e2e4e139"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset1's training datasets & dataloader\n",
        "dataset1_X_train, dataset1_y_train = create_dataset(dataset1_train_dir)\n",
        "dataset1_y_train = dataset1_label_encoder.transform(dataset1_y_train)\n",
        "\n",
        "dataset1_train_dataset = TensorDataset(torch.tensor(dataset1_X_train).float(), torch.from_numpy(dataset1_y_train))\n",
        "dataset1_train_dataloader = DataLoader(dataset1_train_dataset,\n",
        "                                       batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAGtSe-QF-do",
        "outputId": "950cbb49-7757-499d-8d93-5f89c6829dc1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "해당 셀의 코드 중 dataloader 부분의 `shuffle=False` 는 수정하면 안됩니다.\n",
        "\"\"\"\n",
        "\n",
        "dataset1_test_X = []\n",
        "test_list = os.listdir(dataset1_test_dir)\n",
        "for f in test_list:\n",
        "  temp = pd.read_csv(dataset1_test_dir + f)\n",
        "  dataset1_test_X.append(torch.from_numpy(temp.values))\n",
        "\n",
        "dataset1_test_X = pad_sequence(dataset1_test_X, batch_first=True)\n",
        "dataset1_test_dataset = TensorDataset(dataset1_test_X)\n",
        "dataset1_test_dataloader = DataLoader(dataset1_test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "6p5ddmd_GAf9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EDA\n"
      ],
      "metadata": {
        "id": "mPFsOAeTaoeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#사이즈 확인\n",
        "#3차원\n",
        "for x,y in dataset0_train_dataloader:\n",
        "  print(x.size(),y.size())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3HRY93-79Xm",
        "outputId": "f5cde7cf-999c-48ae-e567-0c0525aa4f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 696, 6]) torch.Size([256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#사이즈 확인\n",
        "for x,y in dataset1_train_dataloader:\n",
        "  print(x.size(),y.size())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC2lsm8MPqhR",
        "outputId": "2464bdb1-6596-4d87-e62e-0618bb585bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 800, 6]) torch.Size([256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset0 _ 훈련데이터 확인 (총12414개,696개의 텐서, 텐서는 6개의 값으로 구성)== 데이터 1개당 각각의 클래스 정보(라벨)를 가지고 696개의 메타데이터(요소)가 6개의 시간별로 데이터를 이룸\n",
        "#\n",
        "dataset0_train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3ZmedaqavUz",
        "outputId": "07cd15cd-2669-487b-fd4a-d1b8f0540401"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1.0405e+00,  9.8331e+00,  9.6893e-02,  7.0250e-03,  3.0849e-02,\n",
              "           1.8937e-02],\n",
              "         [ 1.0386e+00,  9.8345e+00,  1.0017e-01,  1.1912e-02,  3.6041e-02,\n",
              "           1.3439e-02],\n",
              "         [ 1.0364e+00,  9.8362e+00,  1.0408e-01,  1.2217e-02,  4.0012e-02,\n",
              "           1.4661e-02],\n",
              "         ...,\n",
              "         [ 7.2082e+00,  1.3439e+00,  6.3675e+00, -3.0543e-04, -1.4355e-02,\n",
              "           6.4141e-03],\n",
              "         [ 7.2011e+00,  1.3510e+00,  6.3652e+00,  1.5272e-03, -1.1912e-02,\n",
              "           3.6652e-03],\n",
              "         [ 7.1944e+00,  1.3577e+00,  6.3629e+00, -3.6652e-03, -5.1924e-03,\n",
              "           1.5272e-03]]), tensor(10))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset0_X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDbsqYNPTUrL",
        "outputId": "e4f6b1f5-9ffe-400e-ac6e-eab3023285e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-4.4663e+00,  2.3236e+00,  8.1045e+00, -4.2455e-02,  9.1630e-04,\n",
              "         3.0849e-02], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CNN+LSTM"
      ],
      "metadata": {
        "id": "xf1wP9rFar9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = nn.Conv1d(in_channels=696 ,out_channels=256,kernel_size=2)\n",
        "n = nn.Conv1d(in_channels=256 ,out_channels=128,kernel_size=2)\n",
        "x = nn.Conv1d(in_channels=128 ,out_channels=64,kernel_size=2)\n",
        "y = nn.Conv1d(in_channels=64 ,out_channels=32,kernel_size=2)\n",
        "z = nn.Flatten()\n",
        "lstm = nn.LSTM(input_size=64,\n",
        "                            hidden_size=32,\n",
        "                            num_layers=2,\n",
        "                            bias=True,\n",
        "                            bidirectional=True,\n",
        "                            batch_first=True)\n",
        "fc_1 = nn.Linear(64, 32)\n",
        "fc_2 = nn.Linear(32, len(dataset0_label_encoder.classes_))\n",
        "\n",
        "input = torch.randn(256, 696, 6)\n",
        "output1 = m(input)\n",
        "output2 = n(output1)\n",
        "output3 = x(output2)\n",
        "output4 = y(output3)\n",
        "output5 = z(output4)\n",
        "output6, hid = lstm(output5)\n",
        "output6 = output6.view(64, -1)\n",
        "output7 = fc_1(output6)\n",
        "output8 = fc_2(output7)\n",
        "#output = output.view(32,-1)"
      ],
      "metadata": {
        "id": "Tsn3JJQRhDii",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "d1d3965f-cc6d-4776-fef5-084845d2fa4e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-6c1c479e8174>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0moutput6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0moutput6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0moutput7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0moutput8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#output = output.view(32,-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x256 and 64x32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output1.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHitVG0vhGXL",
        "outputId": "70050d25-d5d7-419a-9cf1-81e515c8ac09"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 256, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output2.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdooIfFsnPnC",
        "outputId": "34091820-3f80-40c6-8643-f610c45008cf"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 128, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output3.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx5VR3dWnbFI",
        "outputId": "e279b1bc-e8c9-4d9f-fc81-bf30ee394e5d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 64, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output4.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-qBkzCknnG-",
        "outputId": "c55e0657-78e5-4948-b6be-f01c57a77330"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 32, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output5.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jon_Sb1foLRI",
        "outputId": "f48b073d-8685-46ea-bdc7-0c496c55cab9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output6.size(),len(hid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fChAJ21BoWoe",
        "outputId": "35da6186-ede8-4bc7-dda8-c5c9852dbb77"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 32]), 2)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output6.size(),len(hid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lygeUVrUsaK8",
        "outputId": "e64a045f-f7a8-4a43-c69d-5251feca23fe"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 64]), 2)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output7.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp5Qk_K8uy3R",
        "outputId": "44b61641-9854-4ba5-dce9-387c58bcf864"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output8.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoQPDIWruzuW",
        "outputId": "401cb17e-3df0-435a-97e7-719a4602d292"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lstm 예시\n",
        "rnn = nn.LSTM(10, 20, 2)\n",
        "input = torch.randn(5, 3, 10)\n",
        "h0 = torch.randn(2, 3, 20)\n",
        "c0 = torch.randn(2, 3, 20)\n",
        "output, hn = rnn(input, h0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "dfH5oOgGtJ2j",
        "outputId": "e28a87da-cbcb-4db7-c353-16e70b1260da"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-a385bee08768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    753\u001b[0m                         msg = (\"For batched 3-D input, hx and cx should \"\n\u001b[1;32m    754\u001b[0m                                f\"also be 3-D but got ({hx[0].dim()}-D, {hx[1].dim()}-D) tensors\")\n\u001b[0;32m--> 755\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: For batched 3-D input, hx and cx should also be 3-D but got (2-D, 2-D) tensors"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8P83lNItMNQ",
        "outputId": "809d26df-0df0-43b8-a543-144b61efda50"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성 작성\n",
        "batch_size = 256\n",
        "Sequence = 800\n",
        "kernel_size = 2\n",
        "\n",
        "class model_cnn(nn.Module):\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
        "        super(model_cnn,self).__init__()\n",
        "        #800,6 -> 256,6\n",
        "        self.num_classes = num_classes #number of classes\n",
        "        self.num_layers = num_layers #number of layers\n",
        "        self.input_size = input_size #input size\n",
        "        self.hidden_size = hidden_size #hidden state\n",
        "        self.seq_length = seq_length #sequence length\n",
        "\n",
        "        self.conv1d1 = nn.Conv1d(in_channels=seq_length,out_channels=256,kernel_size=2)\n",
        "        #self.maxpooling1 = nn.MaxPool1d(kernel_size)\n",
        "        self.conv1d2 = nn.Conv1d(in_channels=256 ,out_channels=128,kernel_size=2)\n",
        "        self.conv1d3 = nn.Conv1d(in_channels=128 ,out_channels=64,kernel_size=2)\n",
        "        self.conv1d4 = nn.Conv1d(in_channels=64 ,out_channels=32,kernel_size=2)\n",
        "        #self.lstm = nn.LSTM(1,800,256)\n",
        "        #self.maxpooling2 = nn.MaxPool1d(kernel_size)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.lstm = nn.LSTM(input_size=64,\n",
        "                            hidden_size=32,\n",
        "                            num_layers=2,\n",
        "                            bias=True,\n",
        "                            bidirectional=True,\n",
        "                            batch_first=True)\n",
        "        self.fc1 = nn.Linear(64,32)\n",
        "        self.fc2 = nn.Linear(32,num_classes)\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1d1(x)\n",
        "        x = self.relu(x)\n",
        "        #x = self.maxpooling1(x)\n",
        "        x = self.conv1d2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv1d3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv1d4(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.flatten(x)\n",
        "        x,hid = self.lstm(x)\n",
        "        #x = x.view(-1,64)\n",
        "        x = self.relu(x)\n",
        "        #x = self.relu(x[0])\n",
        "        #x = x.view(64, -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        #x = self.fc3(x)\n",
        "        #x = self.relu(x)\n",
        "        x = self.softmax(x)\n",
        "        \n",
        "        return x\n"
      ],
      "metadata": {
        "id": "NfshrKDCGCU2"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 15\n",
        "input_size = 64\n",
        "hidden_size = 32\n",
        "num_layers = 2\n",
        "seq_length = 696\n",
        "\n",
        "model_cnn=model_cnn(num_classes, input_size, hidden_size, num_layers, seq_length)\n",
        "print(model_cnn)"
      ],
      "metadata": {
        "id": "Vy01GxKk9zZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e07529-cc06-4509-cc78-528f7419fc32"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_cnn(\n",
            "  (conv1d1): Conv1d(696, 256, kernel_size=(2,), stride=(1,))\n",
            "  (conv1d2): Conv1d(256, 128, kernel_size=(2,), stride=(1,))\n",
            "  (conv1d3): Conv1d(128, 64, kernel_size=(2,), stride=(1,))\n",
            "  (conv1d4): Conv1d(64, 32, kernel_size=(2,), stride=(1,))\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (lstm): LSTM(64, 32, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=15, bias=True)\n",
            "  (softmax): Softmax(dim=None)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn = model_cnn.to(device)\n",
        "optimizer = torch.optim.Adam(model_cnn.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "jTb9NXzp9aim"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "def Train(model, data_loader):\n",
        "    \n",
        "    running_loss = .0\n",
        "    \n",
        "    model.train()\n",
        "    model = model.to(device)\n",
        "\n",
        "\n",
        "    for idx, (inputs, labels) in enumerate(data_loader):\n",
        "        \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        print(1)\n",
        "        preds = model(inputs.float())\n",
        "        preds = preds.argmax(dim=1).to(device)\n",
        "        #preds = preds.cpu().numpy()\n",
        "        #labels = labels.cpu().numpy()\n",
        "        #print(preds)\n",
        "        #print(labels)\n",
        "        loss = f1_score(labels, preds, average='macro')\n",
        "        print(1)\n",
        "        loss = torch.tensor(loss).to(device)\n",
        "        loss.backward()\n",
        "        print(1)\n",
        "        optimizer.step()\n",
        "        print(1)\n",
        "        running_loss += loss\n",
        "        \n",
        "    train_loss = running_loss/len(data_loader)\n",
        "    train_losses.append(train_loss.detach().numpy())\n",
        "    \n",
        "    print(f'train_loss {train_loss}')"
      ],
      "metadata": {
        "id": "o-MoRUaixiC5"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    print('epochs {}/{}'.format(epoch+1,epochs))\n",
        "    Train(model_cnn, dataset0_train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "w2kiRbiYzgGU",
        "outputId": "ad0fc910-0ad2-41c1-ad6f-9b2bab7fd6b0"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs 1/500\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-189-c1cd027fbf3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs {}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset0_train_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-188-42e51d59915f>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(model, data_loader)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print(preds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#print(labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m     )\n\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f-score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m     )\n\u001b[1;32m   1272\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be class 'SparseSeries' or 'SparseArray'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_multilabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVisibleDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVisibleDeprecationWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;31m# dtype=object should be provided explicitly for ragged arrays,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset1의 test 데이터를 사용한 일반화 성능 확인\n",
        "\n",
        "model_cnn.eval()\n",
        "predicted = []\n",
        "with torch.no_grad():\n",
        "  for idx, x in enumerate(dataset1_test_dataloader):\n",
        "    x = x.permute(0, 2, 1).contiguous().to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model_cnn(x.float())\n",
        "\n",
        "    _, preds = torch.max(output, 1)\n",
        "    predicted.extend(preds.cpu().numpy())\n",
        "  torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "hS1j3WIUGD-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ry38T9luvXth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_preds = pd.DataFrame(predicted, columns=['predicted value'])\n",
        "pd_preds.to_csv('submission.csv')\n",
        "pd_preds.head()"
      ],
      "metadata": {
        "id": "eQ1oDm26GFeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 변경해야함\n",
        "    def __init__(self, hidden_size: int, n_label: int):\n",
        "        super(CustomClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(\"klue/bert-base\")\n",
        "\n",
        "        dropout_rate = 0.1\n",
        "        linear_layer_hidden_size = 32\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "        nn.Linear(hidden_size, linear_layer_hidden_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(linear_layer_hidden_size, n_label)\n",
        "        )\n",
        "\n",
        "        elif args.model == \"transformer\":\n",
        "\n",
        "        hidden_dims = args.hidden_dims # 256\n",
        "        n_heads = args.n_heads # 8\n",
        "        n_layers = args.n_layers # 6\n",
        "        len_max_seq = args.samplet\n",
        "        dropout = args.dropout\n",
        "        d_inner = hidden_dims*4\n",
        "\n",
        "        model = TransformerEncoder(in_channels=args.input_dims, len_max_seq=len_max_seq,\n",
        "            d_word_vec=hidden_dims, d_model=hidden_dims, d_inner=d_inner,\n",
        "            n_layers=n_layers, n_head=n_heads, d_k=hidden_dims//n_heads, d_v=hidden_dims//n_heads,\n",
        "            dropout=dropout, nclasses=args.nclasses)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "        \n",
        "        # BERT 모델의 마지막 레이어의 첫번재 토큰을 인덱싱\n",
        "        last_hidden_states = outputs[0] # last hidden states (batch_size, sequence_len, hidden_size)\n",
        "        cls_token_last_hidden_states = last_hidden_states[:,0,:] # (batch_size, first_token, hidden_size)\n",
        "\n",
        "        logits = self.classifier(cls_token_last_hidden_states)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "xjIhNhAnZMW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(2)Transformer\n"
      ],
      "metadata": {
        "id": "OZaYgZQUpd5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성 작성\n",
        "class model(nn.Module):\n",
        "  def __init__(self, **kargs):\n",
        "    super(model, self).__init__()\n",
        "\n",
        "    self.transformer = TransformerEncoder(in_channels=args.input_dims, len_max_seq=len_max_seq,\n",
        "            d_word_vec=hidden_dims, d_model=hidden_dims, d_inner=d_inner,\n",
        "            n_layers=n_layers, n_head=n_heads, d_k=hidden_dims//n_heads, d_v=hidden_dims//n_heads,\n",
        "            dropout=dropout, nclasses=args.nclasses)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    코드 작성하세요\n",
        "    \"\"\"\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "model = model(**kargs).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "crsy8WtgpiVx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}